---
title: "Weightlifting data from activity monitors"
author: "Proshoon"
date: "December 3, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

Analysis of exercise data captured by activity monitors.
Objective is to predict effectiveness of specific exercise motions based on accelerometer data.
```{r cars}
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
#160 variables. may of them can be removed because they're empty
training <- training[, colSums(is.na(training)) == 0]  #removed lots of columns ; 160->60


#some variables are not important -- x, user name, 3 timestamps, 2 windows; remove them; basically first 7 columns
training <- training[, -c(1:7)]  #first 7 columns removed


#break training data into training and validation
set.seed(9999)  #for re-creating the data
inTrain <- createDataPartition(training$classe, p = 3/4, list = FALSE)
mytrain <- training[inTrain,] #for model building
myvalid <- training[-inTrain,] #for validation




CVcontrol <- trainControl(method = "cv", number = 2) #2-fold cross-validation, 10 was proved too computationally heavy for RF
myrpart <- train(classe ~ ., data = mytrain, method = "rpart", trControl = CVcontrol) #rpart applied
predrpart <- predict(myrpart,myvalid)
confrpart <- confusionMatrix(myvalid$classe, predrpart)
#               Accuracy : 0.4955    quite low   

#Since RPART had very low accuracy, Random Forest was attempted
# THE 3/4 SPLIT (as mentioned above) didn't work because it was computationally very heavy. 
#Was taking too much time. Hence, training was done on 1/10th of the data
#inTrain1 <- createDataPartition(training$classe, p = 1/10, list = FALSE)
#inTrain2 <- createDataPartition(training$classe, p = 1/10, list = FALSE)
#mytrain <- training[inTrain1,] #for model building
#myvalid <- training[inTrain2,] #for validation

myrf <- train(classe ~ ., data = mytrain, method = "rf", trControl = CVcontrol) #rf applied
predrf <- predict (myrf, myvalid)
confrf <- confusionMatrix (myvalid$classe, predrf)
#confrf showed 94% accuracy on validation set
# now we are fairly confident that we have a good model


#process testing data like we processed training+validation data
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings = c("NA", "#DIV/0!", ""))
#160 variables. may of them can be removed because they're empty
testing <- testing[, colSums(is.na(testing)) == 0]  #removed lots of columns ; 160->60
#some variables are not important -- x, user name, 3 timestamps, 2 windows; remove them; basically first 7 columns
testing <- testing[, -c(1:7)]  #first 7 columns removed

testresult <-predict(myrf, testing)
testresult

```
> inTrain1 <- createDataPartition(training$classe, p = 1/10, list = FALSE)
> inTrain2 <- createDataPartition(training$classe, p = 1/10, list = FALSE)
> mytrain <- training[inTrain1,]; myvalid<-training[inTrain2,]
> myrf <- train(classe ~ ., data = mytrain, method = "rf", trControl = CVcontrol, tunelength=1)
> predrf <- predict (myrf, myvalid)
> confrf <- confusionMatrix (myvalid$classe, predrf)
> confrf
Confusion Matrix and Statistics

          ---- details below; ACCURACY and  OUT OF SAMPLE ERROR ----
Prediction   A   B   C   D   E
         A 546   4   5   2   1
         B  13 343  17   1   6
         C   0   7 329   3   4
         D   2   1  30 287   2
         E   0   4   4   3 350

Overall Statistics
                                          
               Accuracy : 0.9445 <<6% OUT OF SAMPLE ERROR; NOT BAD>>          
                 95% CI : (0.9334, 0.9542)
    No Information Rate : 0.2856          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9298          
 Mcnemar's Test P-Value : 4.415e-05       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9733   0.9554   0.8545   0.9696   0.9642
Specificity            0.9914   0.9769   0.9911   0.9790   0.9931
Pos Pred Value         0.9785   0.9026   0.9592   0.8913   0.9695
Neg Pred Value         0.9893   0.9899   0.9655   0.9945   0.9919
Prevalence             0.2856   0.1828   0.1960   0.1507   0.1848
Detection Rate         0.2780   0.1746   0.1675   0.1461   0.1782
Detection Prevalence   0.2841   0.1935   0.1746   0.1640   0.1838
Balanced Accuracy      0.9824   0.9662   0.9228   0.9743   0.9787
> testresult <-predict(myrf, testing)
> testresult
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E




```{r pressure, echo=FALSE}
```

